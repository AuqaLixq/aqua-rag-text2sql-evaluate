#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•è°ƒè¯•æ¨¡å¼æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import json
from pathlib import Path

# æ·»åŠ è„šæœ¬ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent / "scripts"))

def test_debug_mode():
    """æµ‹è¯•è°ƒè¯•æ¨¡å¼é…ç½®"""
    print("ğŸ§ª æµ‹è¯•è°ƒè¯•æ¨¡å¼é…ç½®...")
    
    # 1. æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½
    try:
        import yaml
        config_path = Path(__file__).parent / "configs" / "salila_config_debug.yaml"
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        debug_mode = config.get('evaluation', {}).get('debug_mode', False)
        print(f"âœ… è°ƒè¯•æ¨¡å¼é…ç½®: {debug_mode}")
        
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        return False
    
    # 2. æµ‹è¯•æ•°æ®é›†åŠ è½½
    try:
        dataset_path = Path(__file__).parent / "datasets" / "sakila_test.json"
        
        with open(dataset_path, 'r', encoding='utf-8') as f:
            dataset = json.load(f)
        
        print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸï¼Œå…± {len(dataset)} æ¡æ•°æ®")
        print(f"   ç¬¬ä¸€æ¡æ•°æ®: {dataset[0].get('question', 'N/A')}")
        
        # æµ‹è¯•è°ƒè¯•æ¨¡å¼åˆ‡ç‰‡
        debug_dataset = dataset[:1]
        print(f"âœ… è°ƒè¯•æ¨¡å¼æ•°æ®é›†: {len(debug_dataset)} æ¡æ•°æ®")
        
    except Exception as e:
        print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        return False
    
    # 3. æµ‹è¯•è¯„ä¼°å™¨åˆå§‹åŒ–
    try:
        from run_evaluation import SalilaEvaluator
        
        evaluator = SalilaEvaluator(str(config_path))
        print("âœ… è¯„ä¼°å™¨åˆå§‹åŒ–æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
    
    print("\nğŸ‰ è°ƒè¯•æ¨¡å¼æµ‹è¯•é€šè¿‡ï¼")
    print("ç°åœ¨å¯ä»¥è¿è¡Œ: python run_evaluation.py --config ../configs/salila_config_debug.yaml")
    return True

if __name__ == "__main__":
    test_debug_mode()
